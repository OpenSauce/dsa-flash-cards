- title: "Load Balancing - Round Robin"
  difficulty: "easy"
  tags: ["load balancing", "round robin", "distribution"]
  Front: |
    What is **round-robin** load balancing, and when does it break down?
  Back: |
    Round-robin distributes requests **sequentially** across servers: request 1 goes to server A, request 2 to server B, request 3 to server C, then back to A.

    **When it breaks down:**
    - Servers have **unequal capacity** (a weak server gets the same share as a powerful one)
    - Requests have **unequal cost** (a long-running query gets the same routing as a simple health check)

    **Weighted round-robin** addresses the first issue by assigning proportional shares, but still ignores real-time server load.

    **Interview tip:** Round-robin is the simplest algorithm to explain. Interviewers often ask this as a warm-up before asking about smarter alternatives.

- title: "Load Balancing - L4 vs L7"
  difficulty: "medium"
  tags: ["load balancing", "networking", "L4", "L7"]
  Front: |
    What is the difference between **L4** and **L7** load balancing?
  Back: |
    **L4 (Transport layer)** operates at TCP/UDP level:
    - Routes based on **IP address and port** only
    - Cannot inspect packet payload
    - Very fast — minimal processing overhead
    - Good for: TCP passthrough, UDP streaming, any non-HTTP protocol

    **L7 (Application layer)** operates at HTTP level:
    - Can route based on **URL path, headers, cookies, request body**
    - Enables content-based routing (e.g., `/api/*` to backend servers, `/static/*` to CDN)
    - Can do **SSL termination**, compression, and request rewriting
    - Higher overhead due to full packet inspection

    **Interview tip:** Most web applications use L7 because they need content-aware routing. L4 is chosen when you need raw speed or non-HTTP protocols.

- title: "Load Balancing - Session Stickiness"
  difficulty: "medium"
  tags: ["load balancing", "session", "stickiness", "affinity"]
  Front: |
    How does a load balancer handle **session stickiness**, and what are the trade-offs?
  Back: |
    Sticky sessions (session affinity) route a user to the **same backend server** for the duration of their session.

    **How it works:**
    - **Cookie-based:** Load balancer sets a cookie identifying the target server
    - **IP hash:** Hash the client IP to deterministically pick a server

    **Pros:**
    - Stateful apps work without a shared session store
    - Simple to implement

    **Cons:**
    - **Uneven load distribution** — popular sessions cluster on one server
    - **Server failure loses sessions** — no failover for in-memory state
    - Reduces the effectiveness of scaling out

    **Better approach:** Externalize session state to **Redis or a database**, making all servers stateless and interchangeable. This is the standard recommendation in system design interviews.

- title: "Load Balancing - Health Checks"
  difficulty: "easy"
  tags: ["load balancing", "health checks", "failover"]
  Front: |
    What happens when a server behind a load balancer goes down? How is this detected?
  Back: |
    The load balancer uses **health checks** to detect failed servers and remove them from the pool.

    **Active health checks:** The load balancer periodically sends probe requests (HTTP GET, TCP connect) to each server. If a server fails N consecutive checks, it is marked unhealthy.

    **Passive health checks:** The load balancer monitors error rates from real traffic. If a server returns too many 5xx errors or timeouts, it is removed.

    **Recovery:** Unhealthy servers are re-added to the pool after passing health checks again.

    **Interview tip:** Always mention health checks when discussing load balancers. The follow-up question is usually about graceful degradation — what happens when multiple servers fail simultaneously?

- title: "Load Balancing - Algorithms Overview"
  difficulty: "medium"
  tags: ["load balancing", "algorithms", "comparison"]
  Front: |
    Name **4 load balancing algorithms** and explain when you would choose each.
  Back: |
    1. **Round-robin:** Equal servers, stateless requests. Simplest option.
    2. **Least connections:** Varying request duration. Routes to the server handling the fewest active connections.
    3. **IP hash:** Session affinity without cookies. Same client IP always hits the same server.
    4. **Weighted round-robin:** Heterogeneous server capacity. Powerful servers get proportionally more traffic.

    **Also worth knowing:**
    - **Random:** Surprisingly effective at scale due to the law of large numbers
    - **Least response time:** Routes to the fastest-responding server. Best for latency-sensitive applications.

    **Interview tip:** Interviewers want to hear that you pick the algorithm based on the workload characteristics, not that one algorithm is universally best.
