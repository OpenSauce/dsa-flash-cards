# ── OVERVIEW ────────────────────────────────────────────────────────────────
- title: "Linked List – Overview"
  difficulty: "easy"
  tags: ["linked list", "identify"]
  Front: |
    Which data structure …

    - Consists of nodes connected by **pointers**
    - Allows **O(1)** insertion or deletion at the head
    - Lacks direct (index) access, so search is **O(n)**
  Back: "Linked List"

# ── OPERATION CARDS ─────────────────────────────────────────────────────────
- title: "Linked List – Insert at Head"
  difficulty: "easy"
  tags: ["linked list", "insert"]
  Front: |
    What data structure operation does this implement? What is its time complexity?

    ```go
    type Node struct {
        Val  int
        Next *Node
    }
    head := &Node{Val: 1}
    head  = &Node{Val: 0, Next: head}
    ```
  Back: |
    Insert at head (O(1))

    Creating a new node and pointing it to the old head is constant time. This is the linked list's main advantage over arrays, which require O(n) shifts for front insertion.

- title: "Linked List – Insert at Tail (Singly)"
  difficulty: "easy"
  tags: ["linked list", "insert"]
  Front: |
    What data structure operation does this implement? What is its time complexity?

    ```go
    tail := head
    for tail.Next != nil {
        tail = tail.Next
    }
    tail.Next = &Node{Val: 5}
    ```
  Back: |
    Insert at tail without tail pointer (O(n))

    Without a stored tail pointer you must walk the entire list. Keeping a tail pointer turns this into O(1) — a common optimisation for queue implementations.

- title: "Linked List – Search by Value"
  difficulty: "easy"
  tags: ["linked list", "search"]
  Front: |
    What data structure operation does this implement? What is its time complexity?

    ```go
    cur := head
    target := 3
    for cur != nil && cur.Val != target {
        cur = cur.Next
    }
    ```
  Back: |
    Linear search (O(n))

    No random access means you must traverse node by node. If frequent lookups are needed, consider augmenting the list with a hash map for O(1) access.

- title: "Linked List – Reverse (Iterative)"
  difficulty: "easy"
  tags: ["linked list", "reverse"]
  Front: |
    What data structure operation does this implement? What is its time complexity?

    ```go
    var prev *Node
    cur := head
    for cur != nil {
        nxt := cur.Next
        cur.Next = prev
        prev = cur
        cur = nxt
    }
    head = prev
    ```
  Back: |
    Reverse singly linked list (O(n))

    Uses three pointers to reverse links in one pass. This is one of the most common interview patterns — the key insight is saving `cur.Next` before overwriting it.

# ── INTERVIEW PATTERN CARDS ────────────────────────────────────────────────
- title: "Linked List – Detect Cycle (Floyd's Algorithm)"
  difficulty: "medium"
  tags: ["linked list", "cycle", "interview", "two pointers"]
  Front: |
    **Linked List** — How do you detect if a linked list contains a cycle? What is the time and space complexity?

    ```go
    func hasCycle(head *Node) bool {
        slow, fast := head, head
        for fast != nil && fast.Next != nil {
            slow = slow.Next
            fast = fast.Next.Next
            if slow == fast {
                return true
            }
        }
        return false
    }
    ```
  Back: |
    Floyd's Cycle Detection (Tortoise and Hare) — O(n) time, O(1) space

    The slow pointer moves one step at a time, the fast pointer moves two. If there is a cycle, the fast pointer eventually laps the slow pointer and they meet inside the cycle. If there is no cycle, the fast pointer reaches nil.

    - **Why they must meet:** Once both pointers are inside the cycle, the gap between them shrinks by 1 each step (fast gains 1 step per iteration). They converge in at most one full loop of the cycle.
    - **Finding the cycle start:** After detection, reset one pointer to `head`. Advance both one step at a time — they meet at the cycle's entry point. This works because the distance from head to cycle start equals the distance from the meeting point to cycle start (around the cycle).
    - **Interview tip:** The naive approach uses a hash set (O(n) space). Floyd's algorithm achieves O(1) space — always mention this trade-off.

- title: "Linked List – Find Middle Element"
  difficulty: "easy"
  tags: ["linked list", "interview", "two pointers"]
  Front: |
    **Linked List** — How do you find the middle node in a single pass? What is the time complexity?

    ```go
    func findMiddle(head *Node) *Node {
        slow, fast := head, head
        for fast != nil && fast.Next != nil {
            slow = slow.Next
            fast = fast.Next.Next
        }
        return slow
    }
    ```
  Back: |
    Find middle element using slow/fast pointers — O(n) time, O(1) space

    When the fast pointer reaches the end, the slow pointer is at the middle (for odd-length lists) or the second of the two middle nodes (for even-length lists).

    - **Why it works:** Fast moves at 2x speed, so when fast has traversed the full list, slow has traversed exactly half.
    - **Practical use:** This is a key building block in **merge sort for linked lists** — split the list at the middle, recursively sort each half, then merge.
    - **Variant:** To get the first middle in an even-length list, check `fast.Next != nil && fast.Next.Next != nil` instead.

- title: "Linked List – Merge Two Sorted Lists"
  difficulty: "medium"
  tags: ["linked list", "merge", "interview"]
  Front: |
    **Linked List** — How do you merge two sorted linked lists into one sorted list? What is the time and space complexity?

    ```go
    func mergeTwoLists(l1, l2 *Node) *Node {
        dummy := &Node{}
        cur := dummy
        for l1 != nil && l2 != nil {
            if l1.Val <= l2.Val {
                cur.Next = l1
                l1 = l1.Next
            } else {
                cur.Next = l2
                l2 = l2.Next
            }
            cur = cur.Next
        }
        if l1 != nil { cur.Next = l1 }
        if l2 != nil { cur.Next = l2 }
        return dummy.Next
    }
    ```
  Back: |
    Merge two sorted linked lists — O(n + m) time, O(1) space

    Use a **dummy head node** to simplify edge cases (no special logic for which list's head comes first). Compare heads of both lists, attach the smaller node to the result, and advance that list's pointer. When one list is exhausted, attach the remainder of the other.

    - **Why O(1) space?** Unlike merging arrays, no new nodes are created — existing nodes are re-linked in place. The only extra allocation is the dummy node.
    - **Dummy node pattern:** Creating a placeholder node at the start avoids null-check logic for the first insertion. Return `dummy.Next` to skip it.
    - **Interview tip:** This is the merge step of merge sort on linked lists. Combined with "find middle" (slow/fast pointers) and recursive split, you get O(n log n) linked list sort with O(log n) stack space.
